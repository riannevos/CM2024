{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CM08 - *k*-Nearest Neighbours - voorbeeld 1 en oefening 1 fruit\n",
    "\n",
    "Hogeschool Utrecht (c) 2020\n",
    "\n",
    "Tijmen Muller (tijmen.muller@hu.nl) en nabewerking Joost Vanstreels (joost.vanstreels@hu.nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data inlezen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inlezen tabel met fruit gegevens\n",
    "fruits = pd.read_table('knn_fruit.txt')\n",
    "print('Aantal meetwaarden {0:d}'.format(len(fruits)))\n",
    "fruits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits.value_counts([\"fruit_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De kolommen zijn als volgt:\n",
    "* `fruit_label` is een identificatienummer, overeenkomend met `fruit_name`\n",
    "* `fruit_name` is het fruittype\n",
    "* `fruit_subtype` is het subtype (bijvoorbeeld het soort appel)\n",
    "* `mass` is het gewicht in grammen\n",
    "* `width` is de breedte in cm\n",
    "* `height` is de hoogte in cm\n",
    "* `color_score` is een waarde uit het kleuren spectrum:\n",
    "  * groen: 0.45-0.65\n",
    "  * geel: 0.65-0.75\n",
    "  * oranje: 0.75-0.85\n",
    "  * rood: 0.85-1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maak een dictionary van fruit_label naar fruit_name\n",
    "lookup_fruit_name = dict(zip(fruits['fruit_label'].unique(),fruits['fruit_name'].unique()))\n",
    "lookup_fruit_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aanpak volgens werkwijze `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Kies het modeltype\n",
    "\n",
    "We kiezen _k_-Nearest Neighbours (`KNeighborsClassifier`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Organiseer de data\n",
    "\n",
    "Onze feature matrix `X` bestaat uit de kolommen `mass`, `width` en `height`: dit zijn de kenmerken waar _vanuit_ we willen voorspellen.\n",
    "\n",
    "Onze target vector `y` bestaat uit de kolom `fruit_label`: dit is het resultaat waar we _naartoe_ willen voorspellen (bij _k_-NN moet deze numeriek zijn, ookal is het een klasse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fruits[['mass','width','height']]\n",
    "y = fruits['fruit_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creëer een train- en validatieset\n",
    "\n",
    "De methode `sklearn.model_selection.train_test_split()` deelt de feature matrix en de result vector gerandomiseerd op in een train- en een validatieset (ook wel: testset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits in train en test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "print(f'{len(X_train)} trainwaarden, {len(X_test)} testwaarden: {len(X_train)*100/len(fruits):.1f}%/{len(X_test)*100/len(fruits):.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Kies de hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.set_params(n_neighbors = 5, weights = 'uniform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train het model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Valideer het model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het model is te valideren met de validatieset. Het model heeft de validatieset nog niet gezien (alleen de trainset is gebruikt om het model te trainen). Het model kan de resultaten voorspellen op de _feature matrix_ van de validatieset. Door de uitkomsten (voorspeld resultaat) te vergelijken met de _target vector_ van de validatieset (de échte waarden) kunnen we zien hoe goed het model voorspeld.\n",
    "\n",
    "We kunnen de methode `sklearn.metrics.accuracy_score()` gebruiken om de voorspelde waarde en de echte waarde te vergelijken, dit geeft een percentage 'goed voorspeld'. _k_-NN heeft ook zijn eigen methode `score()`, deze doet hetzelfde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "53% is natuurlijk niet zo'n goede score. Om te bepalen _hoe_ goed (of slecht) de score is, is het goed om na te denken over een baseline. Als we heel naïef/dom zouden voorspellen, wat voor score zouden we dan behalen? In dit voorbeeld zouden we bijvoorbeeld kunnen kijken welk fruittype het vaakst voorkomt en elk stuk fruit in die klasse plaatsen (best dom, toch?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits.groupby('fruit_name').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'apple' en 'orange' komen het vaakst voor, laten we 'orange' kiezen. Deze heeft `fruit_label` = 3, dus in onze 'naieve' voorspelling is het resultaat _altijd_ een 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_naive = np.full(len(y_pred), 3)\n",
    "print(f\"Resultaatvector bij 'dom' voorspellen: {y_naive}\\nBaseline score: {accuracy_score(y_test, y_naive)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dus als we naief voorspellen, behalen we dezelfde score! Dat is niet best...\n",
    "\n",
    "Een andere handige referentie is de score op de *trainset*. Dit zijn de waardes _waarop_ het model heeft getraind, dus hierop zou het model natuurlijk goed moeten scoren (het model heeft zich immers op die waarden gebaseerd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = knn.predict(X_train)\n",
    "print(f\"Score bij voorspellen op de trainset: {accuracy_score(y_train, y_train_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dat is een veel betere voorspellingsscore -- blijkbaar voorspelt het model op de trainingswaarden wél goed en op de validatiewaarden niet. In zo'n geval zou er sprake kunnen zijn van _overfitting_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu willen we natuurlijk graag inzicht  _waarom_ het model niet goed scoort. Bij classificatie kunnen we daarvoor een confusion matrix gebruiken: deze vergelijkt de voorspelde waarde met de echte waarde. We kunnen dit doen met de methode `sklearn.metrics.confusion_matrix()` (geeft een NumPy `array` terug) en vervolgens visualiseren met bijvoorbeeld Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Maak van de array een pandas dataframe om te visualiseren\n",
    "df_cm = pd.DataFrame(cm, \n",
    "                     index = [lookup_fruit_name[i+1] for i in range(4)], \n",
    "                     columns = [lookup_fruit_name[i+1] for i in range(4)])\n",
    "\n",
    "print(cm)\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 5), dpi=100)\n",
    "\n",
    "ax = sns.heatmap(df_cm, annot=True, cmap='Greens')\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "\n",
    "ax.set_xlabel('voorspelde waarde')\n",
    "ax.set_ylabel('echte waarde')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Voorspel nieuwe data\n",
    "\n",
    "We kunnen nu het fruittype voorspellen van een nieuw meetpunt op basis van de kenmerken `mass`, `width` en `length` (met helaas maar een lage betrouwbaarheid, vanwege de lage voorspellingsscore). Bijvoorbeeld: wat voor fruittype is een nieuw stuk fruit met massa 150, breedte 6.5 en hoogte 7?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_feat = [150,6.5,7.0]\n",
    "fruit_pred = knn.predict([fruit_feat])\n",
    "print(fruit_pred)\n",
    "print(f\"Voorspelling: fruit_label = {fruit_pred[0]}, fruit_name = {lookup_fruit_name[fruit_pred[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als je niet beter zou weten, zou je klakkeloos aannemen dat dit stuk fruit een appel is. Maar als je kijkt naar de waarschijnlijkheden van de voorspelling, zie je dat het model niet zo zeker van z'n zaak is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_pred_proba = knn.predict_proba([fruit_feat])\n",
    "print(fruit_pred_proba)\n",
    "print(f\"Voorspelling: fruit_label_proba = {fruit_pred_proba[0,0]}, fruit_name = {lookup_fruit_name[1]}\")\n",
    "print(f\"Voorspelling: fruit_label_proba = {fruit_pred_proba[0,1]}, fruit_name = {lookup_fruit_name[2]}\")\n",
    "print(f\"Voorspelling: fruit_label_proba = {fruit_pred_proba[0,2]}, fruit_name = {lookup_fruit_name[3]}\")\n",
    "print(f\"Voorspelling: fruit_label_proba = {fruit_pred_proba[0,3]}, fruit_name = {lookup_fruit_name[4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oefening\n",
    "\n",
    "Bedenk verschillende aanpassingen die een beter resultaat zouden kunnen opleveren. Voer een variant uit en verifieer het resultaat. Het is mogelijk om een score van 1.0 op deze testset te halen!\n",
    "\n",
    "Merk op: probeer eerst zelf op basis van de theorie van de afgelopen colleges na te denken over acties die je uit kunt voeren om een model te verbeteren. Denk bijvoorbeeld aan de Supervised Learning workflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPOILER ALERT\n",
    "\n",
    "\n",
    "##\n",
    "\n",
    "##\n",
    "\n",
    "##\n",
    "\n",
    "##\n",
    "\n",
    "##\n",
    "\n",
    "## HIERONDER STAAN DE TIPS\n",
    "\n",
    "\n",
    "##\n",
    "\n",
    "##\n",
    "\n",
    "##\n",
    "\n",
    "##\n",
    "\n",
    "##\n",
    "## DENK EERST ZELF NA!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbetering 1. Hyperparameters aanpassen.\n",
    "In het voorbeeld wordt _k_ = 5 gekozen. Controleer of er verbetering is als je een andere waarde voor _k_ kiest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbetering 2. Features toevoegen.\n",
    "\n",
    "In het voorbeeld worden alleen `mass`, `width`, `height` als feature gebruikt. Controleer of er verbetering is als je `color_score` toevoegt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbetering 3. Normaliseren\n",
    "\n",
    "In het voorbeeld zijn de features niet genormaliseerd. Controleer of er verbetering is als je de features normaliseert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verbetering 4. Hyperparameters nog verder aanpassen.\n",
    "In het voorbeeld wordt met een uniforme gewicht gewerkt. Wat gebeurt er als je het gewicht laat afhangen van de distance?\n",
    "\n",
    "Tip: speel ook nog even met de hoogte voor k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
